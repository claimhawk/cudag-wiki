# CUDAG - ComputerUseDataAugmentedGeneration

## 1. Overview

CUDAG is a domain-specific framework for generating synthetic training data for Vision-Language Models (VLMs) focused on computer use scenarios — such as screen interactions, UI rendering, and task-based data augmentation. It adopts a Rails-like MVC-inspired architecture to simplify the creation of data generators for complex UIs, enabling developers to declaratively define screens, manage dynamic state, render images, and orchestrate interaction logic.

The core problem CUDAG solves is the lack of scalable, reproducible, and configurable methods for generating high-fidelity, diverse, and contextually rich synthetic UI data for training VLMs that must understand and interact with computer interfaces. This is especially critical for applications like screen readers, AI agents, accessibility tools, and automated UI testing.

CUDAG abstracts away the complexity of image composition, coordinate management, and dynamic content generation by providing a structured, composable system where developers define:

- **Screens** — declarative UI templates (e.g., `src/cudag/core/screen.py`)
- **State** — dynamic data that populates the screen (e.g., `state.py`)
- **Renderers** — image generation logic (e.g., `src/cudag/core/renderer.py`)
- **Tasks** — interaction logic (e.g., `src/cudag/core/task.py`)
- **Models** — domain-specific data types with generators (e.g., `src/cudag/core/models.py`)

This allows developers to rapidly prototype and scale data generation pipelines for specific domains (e.g., medical claims, financial dashboards, or wiki interfaces) without writing low-level drawing or coordinate logic.

---

## 2. Architecture

The codebase follows a modular, layered architecture with clear separation of concerns. Key directories and their purposes:

### `src/cudag/`
The core framework codebase.

- `__init__.py` — Entry point and package initialization.
- `core/` — Contains the main components of the framework:
  - `screen.py` — Defines screen structure and layout.
  - `task.py` — Defines interaction logic (e.g., mouse clicks, scrolling).
  - `renderer.py` — Handles image composition and output.
  - `models.py` — Domain-specific data models (e.g., `Patient`, `Provider`).
  - `config.py` — Configuration loading and validation.
  - `coords.py` — Coordinate system utilities (e.g., grid positioning).
  - `drawing.py` — Low-level drawing primitives (e.g., text, shapes).
  - `icon.py`, `taskbar.py`, `grid.py`, `data_grid.py` — UI component abstractions.
  - `scroll_task.py`, `iconlist_task.py` — Specific task implementations.

### `tests/`
Automated test suite for validating framework behavior.

- All test files (`test_screen.py`, `test_task.py`, `test_renderer.py`, etc.) validate core components.
- Tests reference `DocGenerator` class — likely a placeholder or base class for app-specific generators (e.g., `wiki-agent`), indicating that apps are expected to inherit from or instantiate this base class.
- **Note**: The repeated error `Lookup failed for Cls 'DocGenerator' from the 'wiki-agent' app: App 'wiki-agent' not found` suggests that the test suite is currently broken or incomplete — likely due to missing app registration or mocking.

### `scripts/`
Utility scripts for specific use cases.

- `chandra_ocr_modal.py` — Likely a script for generating OCR-modaled UIs (e.g., for Chandra or similar systems).

### `assets/`
Static assets used as base templates.

- `base.png` — Full screen template.
- `grid_blank.png` — Blank grid overlays or headers.
- Fonts and other UI assets.

### `config/`
Project-specific configuration.

- `dataset.yaml` — Defines dataset parameters, output paths, and generator configurations.

### `models/`
Domain-specific data models with generators.

- E.g., `Patient`, `Provider`, `Claim` — each with their own generator logic.

### `tasks/`
Task implementations for interaction logic.

- E.g., `ClickTask`, `ScrollTask`, `DragTask` — each implementing specific interaction behaviors.

### `datasets/`
Output directory for generated images (gitignored).

---

## 3. Key Components

### `Screen` (src/cudag/core/screen.py)
Defines the declarative UI structure. It’s a container for components like grids, icons, text fields, and overlays. Developers define screen layout using a DSL-like syntax or class-based composition.

### `State` (state.py)
A dataclass that holds dynamic values to populate the screen. It’s typically generated by the `Model` generators and passed to the `Screen` and `Renderer`.

### `Renderer` (src/cudag/core/renderer.py)
The core image generation engine. It takes a `Screen` and `State`, applies coordinate transformations, and renders the final image using drawing primitives from `drawing.py`.

### `Task` (src/cudag/core/task.py)
Defines interaction logic — e.g., mouse clicks, keyboard inputs, scroll events. Tasks are executed in sequence or conditionally to generate “interaction-aware” data.

### `Model` (src/cudag/core/models.py)
Domain-specific data types (e.g., `Patient`, `Claim`) with associated generators. Each model defines how to generate its data and how to map it to UI components.

### `Config` (src/cudag/core/config.py)
Loads and validates configuration files (e.g., `dataset.yaml`). Defines parameters like image dimensions, output paths, number of samples, and generator configurations.

### `Coords` (src/cudag/core/coords.py)
Manages coordinate systems — e.g., pixel positions, grid offsets, scaling. Used to position UI elements accurately.

### `Drawing` (src/cudag/core/drawing.py)
Low-level drawing primitives — e.g., `draw_text`, `draw_rectangle`, `draw_icon`. These are used by the `Renderer` to compose the final image.

---

## 4. Data Flow

The data flow in CUDAG follows a clear pipeline:

1. **Model Generation** — Domain models (e.g., `Patient`) generate dynamic data instances using their own generators (e.g., `PatientGenerator`).

2. **State Construction** — The generated data is assembled into a `State` dataclass, which is passed to the `Screen`.

3. **Screen Composition** — The `Screen` uses the `State` to render UI components (e.g., text fields, buttons, grids) using coordinate systems and component definitions.

4. **Renderer Execution** — The `Renderer` takes the `Screen` and `State`, applies transformations, and renders the final image using `drawing.py` primitives.

5. **Task Execution** — Optional interaction tasks (e.g., `ClickTask`) are executed on the rendered image to simulate user interaction, generating “action-aware” data.

6. **Output** — The final image (and optionally, metadata) is saved to the `datasets/` directory.

This flow is orchestrated via the CLI (`cudag new`, `cudag generate`) and the `DocGenerator` (or app-specific generator) class, which ties together models, tasks, and renderers.

---

## 5. Getting Started

### Step 1: Install CUDAG

```bash
# Install globally
uvx pip install cudag
```

### Step 2: Create a New Generator Project

```bash
# Generate a new project
cudag new claim-window-generator

# Navigate into the project
cd claim-window-generator
```

This creates the project structure:

```
claim-window-generator/
├── assets/
├── config/
│   └── dataset.yaml
├── models/
├── tasks/
├── screen.py
├── state.py
├── renderer.py
└── datasets/
```

### Step 3: Define Your Domain Model

In `models/`, create a Python file (e.g., `claim.py`) with a dataclass and generator:

```python
# models/claim.py
from dataclasses import dataclass
from typing import Optional

@dataclass
class Claim:
    claim_id: str
    patient_name: str
    provider: str
    amount: float

class ClaimGenerator:
    def generate(self) -> Claim:
        return Claim(
            claim_id=f"CLAIM-{random.randint(1000, 9999)}",
            patient_name=names.get_full_name(),
            provider=providers.sample(),
            amount=round(random.uniform(100, 5000), 2)
        )
```

### Step 4: Define Screen and State

In `screen.py`, define the UI layout:

```python
# screen.py
from cudag.core.screen import Screen
from cudag.core.coords import Coord

class ClaimScreen(Screen):
    def __init__(self, state: State):
        super().__init__(state)
        self.add_text("Claim ID: ", Coord(10, 10))
        self.add_text(f"{state.claim.claim_id}", Coord(100, 10))
        self.add_text("Patient: ", Coord(10, 30))
        self.add_text(f"{state.claim.patient_name}", Coord(100, 30))
        # ... add more components
```

In `state.py`, define the dataclass:

```python
# state.py
from dataclasses import dataclass

@dataclass
class State:
    claim: Claim
```

### Step 5: Define Renderer and Task

In `renderer.py`, implement image generation:

```python
# renderer.py
from cudag.core.renderer import Renderer

class ClaimRenderer(Renderer):
    def render(self, screen: Screen, state: State) -> Image:
        return screen.render(state)
```

In `tasks/`, define interaction logic:

```python
# tasks/claim_task.py
from cudag.core.task import Task

class ClaimClickTask(Task):
    def execute(self, screen: Screen, state: State) -> Image:
        # Simulate clicking on claim ID
        return screen.click(Coord(150, 10))
```

### Step 6: Configure and Generate

In `config/dataset.yaml`:

```yaml
output_dir: datasets
num_samples: 100
models:
  - claim: ClaimGenerator
tasks:
  - claim_click: ClaimClickTask
```

Run generation:

```bash
make generate
```

This will generate 100 synthetic claim UI images with interaction data, saved to `datasets/`.

---

## Notes for Developers

- The test suite currently fails due to missing `wiki-agent` app registration. To fix, ensure that the `DocGenerator` class is properly registered in the framework or that the test suite is updated to mock or skip app-specific dependencies.
- Use `make check` before committing to ensure code quality.
- The `cudag new` command generates a boilerplate project — customize `screen.py`, `state.py`, `renderer.py`, and `tasks/` to match your domain.
- All components are designed to be composable — you can mix and match models, screens, tasks, and renderers to create complex data generation pipelines.

--- 

This framework is designed for rapid prototyping and scaling of synthetic UI data generation for VLM training. It abstracts away the complexity of image composition, making it easier to focus on domain-specific logic.